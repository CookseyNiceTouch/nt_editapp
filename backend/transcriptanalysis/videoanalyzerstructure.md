# VideoAnalyzer JSON Structure

This document describes the structure and format of JSON files produced by the VideoAnalyzer tool, designed to be easily parsed by AI systems.

## Overview

The JSON output represents a frame-accurate transcription of a video file with speaker detection. Transcription is performed by AssemblyAI's API with accurate word-level timestamps that are converted to frame numbers for video editing applications.

## Top-Level Structure

```json
{
  "file_name": "20250509_MTC_2206.MP4",
  "fps": 25.0,
  "duration_frames": 26616,
  "speakers": ["A", "B"],
  "full_transcript": "I do, because I just. I got too far ahead of myself. Oh, yeah, yeah. Sometimes you're like, oh, what am I saying? Next...",
  "words": [
    {
      "word": "I",
      "speaker": "A",
      "frame_in": 2,
      "frame_out": 5
    },
    {
      "word": "do,",
      "speaker": "A",
      "frame_in": 5,
      "frame_out": 10
    }
    // Additional words...
  ]
}
```

## Field Descriptions

### Metadata Fields

| Field | Type | Description |
|-------|------|-------------|
| `file_name` | string | The original filename of the processed video |
| `fps` | number (float) | Frames per second of the video |
| `duration_frames` | number (integer) | Total number of frames in the video |
| `speakers` | array of strings | List of unique speaker identifiers found in the transcript (typically "A", "B", etc.) |
| `full_transcript` | string | Complete text transcript of the entire video |

### Words Array

The `words` array contains objects representing individual words detected in the transcript, with the following properties:

| Field | Type | Description |
|-------|------|-------------|
| `word` | string | The transcribed word |
| `speaker` | string | Speaker identifier associated with this word (e.g., "A", "B") |
| `frame_in` | number (integer) | Starting frame where the word begins |
| `frame_out` | number (integer) | Ending frame where the word ends |

## Frame Calculation

Frame numbers are calculated from AssemblyAI's millisecond timestamps using the formula:

```
frame_in = round((start_time_ms / 1000) * fps)
frame_out = round((end_time_ms / 1000) * fps)
```

If `frame_out` equals `frame_in` (for very short words), `frame_out` is set to `frame_in + 1` to ensure a minimum word duration of one frame.

## Speaker Detection

Speaker labels are generated by AssemblyAI's speaker diarization technology. The system:

1. Analyzes the audio to identify different speakers
2. Assigns each speaker a unique identifier (typically "A", "B", "C", etc.)
3. Tags each word with its corresponding speaker identifier

For example, in a conversation between two people:

```json
[
  {
    "word": "Hi,",
    "speaker": "A",
    "frame_in": 294,
    "frame_out": 303
  },
  {
    "word": "I'm",
    "speaker": "A",
    "frame_in": 303,
    "frame_out": 309
  },
  {
    "word": "Cooksey.",
    "speaker": "A",
    "frame_in": 309,
    "frame_out": 326
  },
  {
    "word": "And",
    "speaker": "B",
    "frame_in": 342,
    "frame_out": 349
  },
  {
    "word": "I'm",
    "speaker": "B",
    "frame_in": 349,
    "frame_out": 355
  },
  {
    "word": "Paul.",
    "speaker": "B",
    "frame_in": 355,
    "frame_out": 364
  }
]
```

## Custom Spelling

The VideoAnalyzer supports custom spelling corrections via AssemblyAI's custom_spelling feature. This allows you to specify:

```json
[
  {
    "from": ["misspelled", "mispelled"],
    "to": "misspelled"
  }
]
```

## Error Format

If processing fails, the JSON will have a different structure:

```json
{
  "error": "Error message describing what went wrong",
  "timestamp": "2023-10-01T15:00:00Z"
}
```

## Parsing Guidelines for AI

1. **Speaker Consistency**: All entries in the `words` array have speaker values that match entries in the `speakers` array.

2. **Frame Range Validation**: All frame numbers are non-negative and less than `duration_frames`.

3. **Sequential Word Timing**: Words appear in chronological order, with `frame_in` values generally increasing.

4. **Speaker Groups**: Words from the same speaker are often grouped together in the `words` array.

5. **Transcript Reconstruction**: The complete transcript is provided in `full_transcript`, but you can also reconstruct it from the words array.


## JSON Schema

For validation purposes, the following JSON Schema can be used:

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": ["file_name", "fps", "duration_frames", "speakers", "full_transcript", "words"],
  "properties": {
    "file_name": {
      "type": "string",
      "description": "Original filename of the video"
    },
    "fps": {
      "type": "number",
      "description": "Frames per second of the video"
    },
    "duration_frames": {
      "type": "integer",
      "description": "Total number of frames in the video"
    },
    "speakers": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "List of unique speaker identifiers"
    },
    "full_transcript": {
      "type": "string",
      "description": "Complete transcript text"
    },
    "words": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["word", "speaker", "frame_in", "frame_out"],
        "properties": {
          "word": {
            "type": "string"
          },
          "speaker": {
            "type": "string"
          },
          "frame_in": {
            "type": "integer",
            "minimum": 0
          },
          "frame_out": {
            "type": "integer",
            "minimum": 0
          }
        }
      }
    }
  },
  "additionalProperties": false
}
```

